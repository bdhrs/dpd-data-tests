{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test all conditions match set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from pandas_ods_reader import read_ods\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "import os\n",
    "import time\n",
    "import stat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ignore warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\", 'This pattern has match groups')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "setup time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.now()\n",
    "now = now.strftime(\"%Y/%m/%d %H:%M:%S\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "make new dpd.csv?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "08:17:42 pandas version 1.3.4\n",
      "08:17:42 converting ods to csv\n",
      "08:17:42 reading ods_file\n",
      "08:18:12 removing first row\n",
      "08:18:12 re-adding headers\n",
      "08:18:12 cleaning messed up cells\n",
      "08:18:12 find out why are they messed up?!\n",
      "08:18:12 writing data frame to /home/bhikkhu/Bodhirasa/Dropbox/dpd/csvs/dpd.csv\n",
      "08:18:13 printing data frame\n",
      "08:18:13 re-importing csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "1              Pāli1                                              Pāli2   Fin  \\\n",
      "2      Abbreviations                                      Abbreviations  None   \n",
      "3               Help  The is the vocative singular of nouns, and 3rd...  None   \n",
      "4                  ā                                                 ā-     √   \n",
      "5                a 1                                                  a     √   \n",
      "6                a 2                                                 a-    √√   \n",
      "...              ...                                                ...   ...   \n",
      "45427    esanāpasuta                                        esanāpasuta     √   \n",
      "45428  upekkhāvihāra                                      upekkhāvihāro     √   \n",
      "45429      kolacuṇṇa                                         kolacuṇṇaṃ     √   \n",
      "45430       kolodaka                                          kolodakaṃ     √   \n",
      "45431     kolavikati                                         kolavikati     √   \n",
      "\n",
      "1                 POS                                            Grammar  \\\n",
      "2                None                                               None   \n",
      "3      Part of speech  Grammatical information including \\n- part of ...   \n",
      "4              prefix                                             prefix   \n",
      "5              letter                                       letter, masc   \n",
      "6              prefix                                             prefix   \n",
      "...               ...                                                ...   \n",
      "45427             adj                                          adj, comp   \n",
      "45428            masc                                         masc, comp   \n",
      "45429              nt                                           nt, comp   \n",
      "45430              nt                                           nt, comp   \n",
      "45431             fem                                          fem, comp   \n",
      "\n",
      "1     Derived from   Neg  Verb Trans  Case  ...          Stem Pattern  \\\n",
      "2             None  None  None  None  None  ...             -    None   \n",
      "3             None  None  None  None  None  ...             -    None   \n",
      "4             None  None  None  None  None  ...             -    None   \n",
      "5             None  None  None  None  None  ...             -    None   \n",
      "6             None  None  None  None  None  ...             -    None   \n",
      "...            ...   ...   ...   ...   ...  ...           ...     ...   \n",
      "45427         None  None  None  None  None  ...    esanāpasut   a adj   \n",
      "45428         None  None  None  None  None  ...  upekkhāvihār  a masc   \n",
      "45429         None  None  None  None  None  ...      kolacuṇṇ    a nt   \n",
      "45430         None  None  None  None  None  ...       kolodak    a nt   \n",
      "45431         None  None  None  None  None  ...     kolavikat   i fem   \n",
      "\n",
      "1                                       Buddhadatta        Date Pāli1 ≠ const  \\\n",
      "2                                              None  2022-02-01          #N/A   \n",
      "3                                              None  2022-02-01           0.0   \n",
      "4                       up to (prep), from, towards  2022-02-01          #N/A   \n",
      "5                                              None  2022-02-01          #N/A   \n",
      "6      prefix ā shortened before a double consonant  2022-02-01           1.0   \n",
      "...                                             ...         ...           ...   \n",
      "45427                                          None  2022-02-01           1.0   \n",
      "45428                                          None  2022-02-01           1.0   \n",
      "45429                                          None  2022-02-01           1.0   \n",
      "45430                                          None  2022-02-01           1.0   \n",
      "45431                                          None  2022-02-01           1.0   \n",
      "\n",
      "1     test dupl Metadata  Data Letter POS = Grammar  \n",
      "2           1.0      yes   5.0   None             x  \n",
      "3           1.0      yes  29.0   None             x  \n",
      "4           1.0     None  12.0      ā          True  \n",
      "5           1.0     None  12.0     a           True  \n",
      "6           1.0     None  17.0     a           True  \n",
      "...         ...      ...   ...    ...           ...  \n",
      "45427       1.0     None  17.0     es          True  \n",
      "45428       1.0     None  16.0     up          True  \n",
      "45429       1.0     None  16.0     ko          True  \n",
      "45430       1.0     None  18.0     ko          True  \n",
      "45431       1.0     None  17.0     ko          True  \n",
      "\n",
      "[45430 rows x 57 columns]\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3758/1360760075.py:12: DtypeWarning: Columns (53,56) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  convert_dpd_ods_to_csv()\n",
      "08:18:13 writing to dpd with meaning.csv\n"
     ]
    }
   ],
   "source": [
    "# get date and time of dpd.csv\n",
    "test_results_file = \"/home/bhikkhu/Bodhirasa/Dropbox/dpd/csvs/dpd.csv\"\n",
    "test_results_stats = os.stat ( test_results_file )\n",
    "modificationTime = time.ctime ( test_results_stats [stat.ST_MTIME ] )\n",
    "\n",
    "# convert ods to csv\n",
    "from ods_to_csv import convert_dpd_ods_to_csv\n",
    "\n",
    "yn = (input(f\"dpd.csv last modified on {modificationTime}. convert ods to csv?  (y?n) \"))\n",
    "\n",
    "if yn == \"y\":\n",
    "\tconvert_dpd_ods_to_csv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import dpd csv & tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file = \"/home/bhikkhu/Bodhirasa/Dropbox/dpd/csvs/dpd.csv\"\n",
    "pali_df = pd.read_csv (csv_file, sep=\"\\t\", dtype=str, skip_blank_lines=False)\n",
    "pali_df.fillna(\"\", inplace=True)\n",
    "\n",
    "tests_csv_file = \"/home/bhikkhu/Bodhirasa/Dropbox/dpd/dpd data tests/tests.csv\"\n",
    "sheet_index = 1\n",
    "tests_df = pd.read_csv (tests_csv_file, sep=\"\\t\", dtype=str, skip_blank_lines=False)\n",
    "tests_df.fillna(\"\", inplace=True)\n",
    "\n",
    "test_column_count = tests_df.shape[0]\n",
    "row = 0\n",
    "line = row + 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tests.csv data integrity tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pali_df_column_names = list(pali_df.columns)\n",
    "pali_df_column_names.append(\"\")\n",
    "\n",
    "for row in range (0, test_column_count):\n",
    "\n",
    "\tline = row + 2\n",
    "\tsearch_name = (tests_df.iloc[row, 0])\n",
    "\n",
    "\tif search_name == (\"\"):\n",
    "\t\tcontinue\n",
    "\telif re.findall(\"^\\!\", search_name):\n",
    "\t\tcontinue\n",
    "\n",
    "\tsearch_column1 = (tests_df.iloc[row, 1])\n",
    "\tsearch_column2 = (tests_df.iloc[row, 4])\n",
    "\tsearch_column3 = (tests_df.iloc[row, 7])\n",
    "\tsearch_column4 = (tests_df.iloc[row, 10])\n",
    "\tsearch_column5 = (tests_df.iloc[row, 13])\n",
    "\tsearch_column6 = (tests_df.iloc[row, 16])\n",
    "\tprint_column1 = (tests_df.iloc[row, 19])\n",
    "\tprint_column2 = (tests_df.iloc[row, 20])\n",
    "\tprint_column3 = (tests_df.iloc[row, 21])\n",
    "\n",
    "\tif search_column1 not in pali_df_column_names:\n",
    "\t\tprint (f\"{line}. {search_name} search column 1 *{search_column1}* does not exist\")\n",
    "\t\t# txt_file.write (f\"{line}. {search_name} search column 1 *{search_column1}* does not exist\")\n",
    "\tif search_column2 not in pali_df_column_names:\n",
    "\t\tprint (f\"{line}. {search_name} search column 2 *{search_column2}* does not exist\")\n",
    "\t\t# txt_file.write (f\"{line}. {search_name} search column 2 *{search_column2}* does not exist\")\n",
    "\tif search_column3 not in pali_df_column_names:\n",
    "\t\tprint (f\"{line}. {search_name} search column 3 *{search_column3}* does not exist\")\n",
    "\t\t# txt_file.write (f\"{line}. {search_name} search column 3 *{search_column3}* does not exist\")\n",
    "\tif search_column4 not in pali_df_column_names:\n",
    "\t\tprint (f\"{line}. {search_name} search column 4 *{search_column4}* does not exist\")\n",
    "\t\t# txt_file.write (f\"{line}. {search_name} search column 4 *{search_column4}* does not exist\")\n",
    "\tif search_column5 not in pali_df_column_names:\n",
    "\t\tprint (f\"{line}. {search_name} search column 5 *{search_column5}* does not exist\")\n",
    "\t\t# txt_file.write (f\"{line}. {search_name} search column 5 *{search_column5}* does not exist\")\n",
    "\tif search_column6 not in pali_df_column_names:\n",
    "\t\tprint (f\"{line}. {search_name} search column 6 *{search_column6}* does not exist\")\n",
    "\t\t# txt_file.write (f\"{line}. {search_name} search column 6 *{search_column6}* does not exist\")\n",
    "\tif print_column1 not in pali_df_column_names:\n",
    "\t\tprint (f\"{line}. {search_name} print column 1 *{print_column1}* does not exist\")\n",
    "\t\t# txt_file.write (f\"{line}. {search_name} print column 1 *{print_column1}* does not exist\")\n",
    "\tif print_column2 not in pali_df_column_names:\n",
    "\t\tprint (f\"{line}. {search_name} print column 2 *{print_column2}* does not exist\")\n",
    "\t\t# txt_file.write (f\"{line}. {search_name} print column 2 *{print_column2}* does not exist\")\n",
    "\tif print_column3 not in pali_df_column_names:\n",
    "\t\tprint (f\"{line}. {search_name} print column 3 *{print_column3}* does not exist\")\n",
    "\t\t# txt_file.write (f\"{line}. {search_name} print column 3 *{print_column3}* does not exist\")\n",
    "\n",
    "\tsearch_sign1 = (tests_df.iloc[row, 2])\n",
    "\tsearch_sign2 = (tests_df.iloc[row, 5])\n",
    "\tsearch_sign3 = (tests_df.iloc[row, 8])\n",
    "\tsearch_sign4 = (tests_df.iloc[row, 11])\n",
    "\tsearch_sign5 = (tests_df.iloc[row, 14])\n",
    "\tsearch_sign6 = (tests_df.iloc[row, 17])\n",
    "\n",
    "\tif search_sign1 not in [\"equals\", \"does not equal\", \"contains\", \"does not contain\", \"contains word\", \"does not contain word\", \"is empty\", \"is not empty\", \"\"]:\n",
    "\t\tprint (f\"{line}. {search_name} search_sign1 *{search_sign1}* does not exist\")\n",
    "\t\t# txt_file.write (f\"{line}. {search_name} search_sign1 *{search_sign1}* does not exist\")\n",
    "\n",
    "\tif search_sign2 not in [\"equals\", \"does not equal\", \"contains\", \"does not contain\", \"contains word\", \"does not contain word\", \"is empty\", \"is not empty\", \"\"]:\n",
    "\t\tprint (f\"{line}. {search_name} search_sign2 *{search_sign2}* does not exist\")\n",
    "\t\t# txt_file.write (f\"{line}. {search_name} search_sign2 *{search_sign2}* does not exist\")\n",
    "\n",
    "\tif search_sign3 not in [\"equals\", \"does not equal\", \"contains\", \"does not contain\", \"contains word\", \"does not contain word\", \"is empty\", \"is not empty\", \"\"]:\n",
    "\t\tprint (f\"{line}. {search_name} search_sign3 *{search_sign3}* does not exist\")\n",
    "\t\t# txt_file.write (f\"{line}. {search_name} search_sign3 *{search_sign3}* does not exist\")\n",
    "\n",
    "\tif search_sign4 not in [\"equals\", \"does not equal\", \"contains\", \"does not contain\", \"contains word\", \"does not contain word\", \"is empty\", \"is not empty\", \"\"]:\n",
    "\t\tprint (f\"{line}. {search_name} search_sign4 *{search_sign4}* does not exist\")\n",
    "\t\t# txt_file.write (f\"{line}. {search_name} search_sign4 *{search_sign4}* does not exist\")\n",
    "\n",
    "\tif search_sign5 not in [\"equals\", \"does not equal\", \"contains\", \"does not contain\", \"contains word\", \"does not contain word\", \"is empty\", \"is not empty\", \"\"]:\n",
    "\t\tprint (f\"{line}. {search_name} search_sign5 *{search_sign5}* does not exist\")\n",
    "\t\t# txt_file.write (f\"{line}. {search_name} search_sign5 *{search_sign5}* does not exist\")\n",
    "\n",
    "\tif search_sign6 not in [\"equals\", \"does not equal\", \"contains\", \"does not contain\", \"contains word\", \"does not contain word\", \"is empty\", \"is not empty\", \"\"]:\n",
    "\t\tprint (f\"{line}. {search_name} search_sign6 *{search_sign6}* does not exist\")\n",
    "\t\t# txt_file.write (f\"{line}. {search_name} search_sign6 *{search_sign6}* does not exist\")\n",
    "\n",
    "\tline += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "generate test results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open test_results.txt\n",
    "\n",
    "row = 0\n",
    "\n",
    "\n",
    "txt_file = open (\"test_results.txt\", 'w', encoding= \"'utf-8\")\n",
    "txt_file2 = open (\"test_results_all.txt\", 'w', encoding= \"'utf-8\")\n",
    "\n",
    "with open(\"test_results.txt\", 'a') as txt_file:\n",
    "\tline_break = \"~\" * 40\n",
    "\ttxt_file.write (f\"DPD tests {now}\\n\")\n",
    "\ttxt_file.write (f\"{line_break}\\n\")\n",
    "\ttxt_file.write (f\"Notez in Anki\\n\")\n",
    "\ttxt_file.write (f\"Notez in Google Sheets\\n\")\n",
    "\ttxt_file.write (f\"Notez on page\\n\")\n",
    "\n",
    "# define variables\n",
    "\n",
    "for row in range (0, test_column_count):\n",
    "\tline = row + 2\n",
    "\t\n",
    "\tsearch_name = (tests_df.iloc[row, 0])\n",
    "\n",
    "\tif search_name == (\"\"):\n",
    "\t\tcontinue\n",
    "\telif re.findall(\"^\\!\", search_name):\n",
    "\t\tcontinue\n",
    "\n",
    "\tsearch_column1 = (tests_df.iloc[row, 1])\n",
    "\tsearch_sign1 = (tests_df.iloc[row, 2])\n",
    "\tsearch_string1 = (tests_df.iloc[row, 3])\n",
    "\n",
    "\tsearch_column2 = (tests_df.iloc[row, 4])\n",
    "\tsearch_sign2 = (tests_df.iloc[row, 5])\n",
    "\tsearch_string2 = (tests_df.iloc[row, 6])\n",
    "\n",
    "\tsearch_column3 = (tests_df.iloc[row, 7])\n",
    "\tsearch_sign3 = (tests_df.iloc[row, 8])\n",
    "\tsearch_string3 = (tests_df.iloc[row, 9])\n",
    "\n",
    "\tsearch_column4 = (tests_df.iloc[row, 10])\n",
    "\tsearch_sign4 = (tests_df.iloc[row, 11])\n",
    "\tsearch_string4 = (tests_df.iloc[row, 12])\n",
    "\n",
    "\tsearch_column5 = (tests_df.iloc[row, 13])\n",
    "\tsearch_sign5 = (tests_df.iloc[row, 14])\n",
    "\tsearch_string5 = (tests_df.iloc[row, 15])\n",
    "\n",
    "\tsearch_column6 = (tests_df.iloc[row, 16])\n",
    "\tsearch_sign6 = (tests_df.iloc[row, 17])\n",
    "\tsearch_string6 = (tests_df.iloc[row, 18])\n",
    "\n",
    "\tprint_column1 = (tests_df.iloc[row, 19])\n",
    "\tprint_column2 = (tests_df.iloc[row, 20])\n",
    "\tprint_column3 = (tests_df.iloc[row, 21])\n",
    "\n",
    "\texceptions = (tests_df.iloc[row, 22])\n",
    "\titerations = int(tests_df.iloc[row, 23])\n",
    "\n",
    "\tif exceptions == \"\":\n",
    "\t\ttest_exceptions = pali_df[\"Pāli1\"].str.contains(\".+\")\n",
    "\tif exceptions != \"\":\n",
    "\t\ttest_exceptions = pali_df[\"Pāli1\"].str.contains(exceptions) == False\n",
    "\t\n",
    "\t# search1\n",
    "\tif search_sign1 == \"equals\":\n",
    "\t\ttest1 = pali_df[search_column1] == (search_string1)\n",
    "\telif search_sign1 == \"does not equal\":\n",
    "\t\ttest1 = pali_df[search_column1] != (search_string1)\n",
    "\telif search_sign1 == \"contains\":\n",
    "\t\ttest1 = pali_df[search_column1].str.contains(search_string1)\n",
    "\telif search_sign1 == \"does not contain\":\n",
    "\t\ttest1 = pali_df[search_column1].str.contains(search_string1) == False\n",
    "\telif search_sign1 == \"contains word\":\n",
    "\t\ttest1 = pali_df[search_column1].str.contains(fr\"\\b{search_string1}\\b\")\n",
    "\telif search_sign1 == \"does not contain word\":\n",
    "\t\ttest1 = pali_df[search_column1].str.contains(fr\"\\b{search_string1}\\b\") == False\n",
    "\telif search_sign1 == \"is empty\":\n",
    "\t\ttest1 = pali_df[search_column1] == (\"\")\n",
    "\telif search_sign1 == \"is not empty\":\n",
    "\t\ttest1 = pali_df[search_column1].str.contains(\".+\") == True\n",
    "\telif search_sign1 == \"\":\n",
    "\t\ttest1 = pali_df[\"Pāli1\"].str.contains(\".+\")\n",
    "\telse:\n",
    "\t\tprint(f\"search1 error\")\n",
    "\n",
    "\t\n",
    "\t# search2\n",
    "\tif search_sign2 == \"equals\":\n",
    "\t\ttest2 = pali_df[search_column2] == (search_string2)\n",
    "\telif search_sign2 == \"does not equal\":\n",
    "\t\ttest2 = pali_df[search_column2] != (search_string2)\n",
    "\telif search_sign2 == \"contains\":\n",
    "\t\ttest2 = pali_df[search_column2].str.contains(search_string2)\n",
    "\telif search_sign2 == \"does not contain\":\n",
    "\t\ttest2 = pali_df[search_column2].str.contains(search_string2) == False\n",
    "\telif search_sign2 == \"contains word\":\n",
    "\t\ttest2 = pali_df[search_column2].str.contains(fr\"\\b{search_string2}\\b\")\n",
    "\telif search_sign2 == \"does not contain word\":\n",
    "\t\ttest2 = pali_df[search_column2].str.contains(fr\"\\b{search_string2}\\b\") == False\n",
    "\telif search_sign2 == \"is empty\":\n",
    "\t\ttest2 = pali_df[search_column2] == (\"\")\n",
    "\telif search_sign2 == \"is not empty\":\n",
    "\t\ttest2 = pali_df[search_column2].str.contains(\".+\") == True\n",
    "\telif search_sign2 == \"\":\n",
    "\t\ttest2 = pali_df[\"Pāli2\"].str.contains(\".+\")\n",
    "\telse:\n",
    "\t\tprint(\"search2 error\")\n",
    "\n",
    "\t# search3\n",
    "\tif search_sign3 == \"equals\":\n",
    "\t\ttest3 = pali_df[search_column3] == (search_string3)\n",
    "\telif search_sign3 == \"does not equal\":\n",
    "\t\ttest3 = pali_df[search_column3] != (search_string3)\n",
    "\telif search_sign3 == \"contains\":\n",
    "\t\ttest3 = pali_df[search_column3].str.contains(search_string3)\n",
    "\telif search_sign3 == \"does not contain\":\n",
    "\t\ttest3 = pali_df[search_column3].str.contains(search_string3) == False\n",
    "\telif search_sign3 == \"contains word\":\n",
    "\t\ttest3 = pali_df[search_column3].str.contains(fr\"\\b{search_string3}\\b\")\n",
    "\telif search_sign3 == \"does not contain word\":\n",
    "\t\ttest3 = pali_df[search_column3].str.contains(fr\"\\b{search_string3}\\b\") == False\n",
    "\telif search_sign3 == \"is empty\":\n",
    "\t\ttest3 = pali_df[search_column3] == (\"\")\n",
    "\telif search_sign3 == \"is not empty\":\n",
    "\t\ttest3 = pali_df[search_column3].str.contains(\".+\") == True\n",
    "\telif search_sign3 == \"\":\n",
    "\t\ttest3 = pali_df[\"Pāli1\"].str.contains(\".+\")\n",
    "\telse:\n",
    "\t\tprint(\"search3 error\")\n",
    "\n",
    "\t# search4\n",
    "\tif search_sign4 == \"equals\":\n",
    "\t\ttest4 = pali_df[search_column4] == (search_string4)\n",
    "\telif search_sign4 == \"does not equal\":\n",
    "\t\ttest4 = pali_df[search_column4] != (search_string4)\n",
    "\telif search_sign4 == \"contains\":\n",
    "\t\ttest4 = pali_df[search_column4].str.contains(search_string4)\n",
    "\telif search_sign4 == \"does not contain\":\n",
    "\t\ttest4 = pali_df[search_column4].str.contains(search_string4) == False\n",
    "\telif search_sign4 == \"contains word\":\n",
    "\t\ttest4 = pali_df[search_column4].str.contains(fr\"\\b{search_string4}\\b\")\n",
    "\telif search_sign4 == \"does not contain word\":\n",
    "\t\ttest4 = pali_df[search_column4].str.contains(fr\"\\b{search_string4}\\b\") == False\n",
    "\telif search_sign4 == \"is empty\":\n",
    "\t\ttest4 = pali_df[search_column4] == (\"\")\n",
    "\telif search_sign4 == \"is not empty\":\n",
    "\t\ttest4 = pali_df[search_column4].str.contains(\".+\") == True\n",
    "\telif search_sign4 == \"\":\n",
    "\t\ttest4 = pali_df[\"Pāli1\"].str.contains(\".+\")\n",
    "\telse:\n",
    "\t\tprint(\"search4 error\")\n",
    "\n",
    "\t# search5\n",
    "\tif search_sign5 == \"equals\":\n",
    "\t\ttest5 = pali_df[search_column5] == (search_string5)\n",
    "\telif search_sign5 == \"does not equal\":\n",
    "\t\ttest5 = pali_df[search_column5] != (search_string5)\n",
    "\telif search_sign5 == \"contains\":\n",
    "\t\ttest5 = pali_df[search_column5].str.contains(search_string5)\n",
    "\telif search_sign5 == \"does not contain\":\n",
    "\t\ttest5 = pali_df[search_column5].str.contains(search_string5) == False\n",
    "\telif search_sign5 == \"contains word\":\n",
    "\t\ttest5 = pali_df[search_column5].str.contains(fr\"\\b{search_string5}\\b\")\n",
    "\telif search_sign5 == \"does not contain word\":\n",
    "\t\ttest5 = pali_df[search_column5].str.contains(fr\"\\b{search_string5}\\b\") == False\n",
    "\telif search_sign5 == \"is empty\":\n",
    "\t\ttest5 = pali_df[search_column5] == (\"\")\n",
    "\telif search_sign5 == \"is not empty\":\n",
    "\t\ttest5 = pali_df[search_column5].str.contains(\".+\") == True\n",
    "\telif search_sign5 == \"\":\n",
    "\t\ttest5 = pali_df[\"Pāli1\"].str.contains(\".+\")\n",
    "\telse:\n",
    "\t\tprint(\"search5 error\")\n",
    "\n",
    "\t# search6\n",
    "\tif search_sign6 == \"equals\":\n",
    "\t\ttest6 = pali_df[search_column6] == (search_string6)\n",
    "\telif search_sign6 == \"does not equal\":\n",
    "\t\ttest6 = pali_df[search_column6] != (search_string6)\n",
    "\telif search_sign6 == \"contains\":\n",
    "\t\ttest6 = pali_df[search_column6].str.contains(search_string6)\n",
    "\telif search_sign6 == \"does not contain\":\n",
    "\t\ttest6 = pali_df[search_column6].str.contains(search_string6) == False\n",
    "\telif search_sign6 == \"contains word\":\n",
    "\t\ttest6 = pali_df[search_column6].str.contains(fr\"\\b{search_string6}\\b\")\n",
    "\telif search_sign6 == \"does not contain word\":\n",
    "\t\ttest6 = pali_df[search_column6].str.contains(fr\"\\b{search_string6}\\b\") == False\n",
    "\telif search_sign6 == \"is empty\":\n",
    "\t\ttest6 = pali_df[search_column6] == (\"\")\n",
    "\telif search_sign6 == \"is not empty\":\n",
    "\t\ttest6 = pali_df[search_column6].str.contains(\".+\") == True\n",
    "\telif search_sign6 == \"\":\n",
    "\t\ttest6 = pali_df[\"Pāli1\"].str.contains(\".+\")\n",
    "\telse:\n",
    "\t\tprint(\"search6 error\")\n",
    "\n",
    "\tfilter = test_exceptions & test1 & test2 & test3 & test4 & test5 & test6\n",
    "\n",
    "\tfiltered_df = pali_df.loc[filter, [print_column1, print_column2, print_column3]]\n",
    "\tall_tests_df = pali_df.loc[filter, [print_column1, print_column2, print_column3]]\n",
    "\n",
    "\n",
    "\tcolumn_count2 = filtered_df.shape[0]\n",
    "\tfiltered_df = filtered_df.head(iterations)\n",
    "\tcolumn_count1 = filtered_df.shape[0]\n",
    "\n",
    "\tcolumn_count3 = all_tests_df.shape[0]\n",
    "\n",
    "\t# print to text file\n",
    "\n",
    "\tif column_count1> 0:\n",
    "\t\twith open(\"test_results.txt\", 'a') as txt_file:\n",
    "\t\t\ttxt_file.write (f\"{line_break}\\n\")\n",
    "\t\t\ttxt_file.write (f\"{line}. {search_name} ({column_count1} of {column_count2})\\n\")\n",
    "\t\t\ttxt_file.write (f\"{line_break}\\n\")\n",
    "\t\t\tfiltered_df.to_csv(txt_file, header=False, index=False, sep=\"\\t\")\n",
    "\t\t\t# txt_file.write (f\"\\n\")\n",
    "\n",
    "\tif column_count1> 0:\n",
    "\t\twith open(\"test_results_all.txt\", 'a') as txt_file2:\n",
    "\t\t\ttxt_file2.write (f\"{line_break}\\n\")\n",
    "\t\t\ttxt_file2.write (f\"{line}. {search_name} ({column_count3})\\n\")\n",
    "\t\t\ttxt_file2.write (f\"{line_break}\\n\")\n",
    "\t\t\tall_tests_df.to_csv(txt_file2, header=False, index=False, sep=\"\\t\")\n",
    "\t\t\t# txt_file.write (f\"\\n\")\n",
    "\n",
    "\tline += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test words in construction exist as headwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# headwords_list = pali_df[\"Pāli1\"].str.replace(\" \\d*\", \"\").tolist()\n",
    "# exceptions_list = [\"ika\", \"iya\", \"ena\", \"*ya\"]\n",
    "\n",
    "# count = 0\n",
    "# text_string = \"\"\n",
    "\n",
    "# for row in range(len(pali_df)): #len(pali_df)\n",
    "# \theadword = pali_df.loc[row, \"Pāli1\"]\n",
    "# \tmeaning = pali_df.loc[row, \"Meaning IN CONTEXT\"]\n",
    "# \tpos = pali_df.loc[row, \"POS\"]\n",
    "# \tconstruction = pali_df.loc[row, \"Construction\"]\n",
    "# \tconstruction = re.sub(\">.+\\ +\", \" + \", construction)\n",
    "# \tconstruction = re.sub(r\"\\+\", \"\", construction)\n",
    "# \tconstruction = re.sub(\">\", \"\", construction)\n",
    "# \tconstruction = re.sub(\"\\(\", \"\", construction)\n",
    "# \tconstruction = re.sub(\"\\)\", \"\", construction)\n",
    "# \tconstruction = re.sub(\"\\n.+\", \"\", construction)\n",
    "# \tconstruction_list = construction.split()\n",
    "# \tpali_root = pali_df.loc[row, \"Pāli Root\"]\n",
    "\n",
    "# \tif meaning != \"\" and pali_root == \"\" and pos != \"sandhi\" and pos != \"idiom\":\n",
    "# \t\tfor item in construction_list:\n",
    "# \t\t\tif item in headwords_list:\n",
    "# \t\t\t\tpass\n",
    "# \t\t\tif item not in headwords_list and item not in exceptions_list:\n",
    "# \t\t\t\tif count <= 10:\n",
    "# \t\t\t\t\ttext_string += f\"{headword}. {item} not in heawords\\n\"\n",
    "# \t\t\t\tcount += 1\n",
    "\n",
    "# with open(\"test_results.txt\", 'a') as txt_file:\n",
    "# \ttxt_file.write (f\"{line_break}\\n\")\n",
    "# \ttxt_file.write (f\"construction not in headword (10/{count})\\n\")\n",
    "# \ttxt_file.write (f\"{line_break}\\n\")\n",
    "# \ttxt_file.write(text_string)\n",
    "# \ttxt_file.write (f\"{line_break}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"test_results.txt\", 'a') as txt_file:\n",
    "\theadings = list(pali_df.columns.values)\n",
    "\ttxt_file.write (f\"\\n\")\n",
    "\ttxt_file.write (f\"{line_break}\\n\")\n",
    "\ttxt_file.write (f\"{headings}\")\n",
    "\n",
    "txt_file.close()\n",
    "txt_file2.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "open test results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<os._wrap_close at 0x7f57a3685180>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.popen('code \"/home/bhikkhu/Bodhirasa/Dropbox/dpd/dpd data tests/test_results.txt\"')\n",
    "import os\n",
    "os.popen('code \"/home/bhikkhu/Bodhirasa/Dropbox/dpd/dpd data tests/test_results_all.txt\"')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8a94588eda9d64d9e9a351ab8144e55b1fabf5113b54e67dd26a8c27df0381b3"
  },
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
